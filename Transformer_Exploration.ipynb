{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOKq69S2fk/26HMsOU939g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliciajnguyen/TransformerExploration/blob/main/Transformer_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High Level Understanding"
      ],
      "metadata": {
        "id": "8UBTtVBC_-L0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background\n",
        "\n",
        "RNNs:\n",
        "*  https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\n",
        "*   https://www.youtube.com/watch?v=UNmqTiOnRfg"
      ],
      "metadata": {
        "id": "uXKj1BVI_-VS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Model Specifics\n",
        "\n",
        "Attention:\n",
        "https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\n",
        "\n",
        "Transformers:\n",
        "https://jalammar.github.io/illustrated-transformer/\n",
        "\n",
        "https://habr.com/en/companies/ods/articles/708672/\n",
        "\n",
        "https://medium.com/@fareedkhandev/create-gpt-from-scratch-using-python-part-1-bd89ccf6206a"
      ],
      "metadata": {
        "id": "OvjzM2eIAFlk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ydRQiVkrAJ2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "hM5n8QBpAYGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers\n",
        "\n",
        "https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021"
      ],
      "metadata": {
        "id": "wgrzhr0mAiTP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ggkVs7-vAauB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT-3 From Scratch\n",
        "\n"
      ],
      "metadata": {
        "id": "FLbXGbOMApr4"
      }
    }
  ]
}